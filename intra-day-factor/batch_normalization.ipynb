{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\.virtualenvs\\kaggle_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\.virtualenvs\\kaggle_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use urllib or similar directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9912422"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\.virtualenvs\\kaggle_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data/train-images-idx3-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-labels-idx1-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28881"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\.virtualenvs\\kaggle_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data/train-labels-idx1-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\.virtualenvs\\kaggle_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1648877"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data/t10k-images-idx3-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-labels-idx1-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4542"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data/t10k-labels-idx1-ubyte.gz"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\.virtualenvs\\kaggle_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetWork():\n",
    "    def __init__(self, initial_weights, activation_fn, use_batch_norm):\n",
    "        \"\"\"\n",
    "        初始化网络对象\n",
    "        :param initial_weights: 权重初始化值，是一个list，list中每一个元素是一个权重矩阵\n",
    "        :param activation_fn: 隐层激活函数\n",
    "        :param user_batch_norm: 是否使用batch normalization\n",
    "        \"\"\"\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.name = \"With Batch Norm\" if use_batch_norm else \"Without Batch Norm\"\n",
    "        \n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        \n",
    "        # 存储训练准确率\n",
    "        self.training_accuracies = []\n",
    "        \n",
    "        self.build_network(initial_weights, activation_fn)\n",
    "        \n",
    "    def build_network(self, initial_weights, activation_fn):\n",
    "        \"\"\"\n",
    "        构建网络图\n",
    "        :param initial_weights: 权重初始化，是一个list\n",
    "        :param activation_fn: 隐层激活函数\n",
    "        \"\"\"\n",
    "        self.input_layer = tf.placeholder(tf.float32, [None, initial_weights[0].shape[0]])\n",
    "        layer_in = self.input_layer\n",
    "        \n",
    "        # 前向计算（不计算最后输出层）\n",
    "        for layer_weights in initial_weights[:-1]:\n",
    "            layer_in = self.fully_connected(layer_in, layer_weights, activation_fn)\n",
    "            \n",
    "        # 输出层\n",
    "        self.output_layer = self.fully_connected(layer_in, initial_weights[-1])\n",
    "    \n",
    "    def fully_connected(self, layer_in, layer_weights, activation_fn=None):\n",
    "        \"\"\"\n",
    "        抽象出的全连接层计算\n",
    "        \"\"\"\n",
    "        # 如果使用BN与激活函数\n",
    "        if self.use_batch_norm and activation_fn:\n",
    "            weights = tf.Variable(layer_weights)\n",
    "            linear_output = tf.matmul(layer_in, weights)\n",
    "            \n",
    "            # 调用BN接口\n",
    "            batch_normalized_output = tf.layers.batch_normalization(linear_output, training=self.is_training)\n",
    "\n",
    "            return activation_fn(batch_normalized_output)\n",
    "        # 如果不使用BN或激活函数（即普通隐层） \n",
    "        else:\n",
    "            weights = tf.Variable(layer_weights)\n",
    "            bias = tf.Variable(tf.zeros([layer_weights.shape[-1]]))\n",
    "            linear_output = tf.add(tf.matmul(layer_in, weights), bias)\n",
    "\n",
    "            return activation_fn(linear_output) if activation_fn else linear_output\n",
    "    \n",
    "    def train(self, sess, learning_rate, training_batches, batches_per_validate_data, save_model=None):\n",
    "        \"\"\"\n",
    "        训练模型\n",
    "        :param sess: TensorFlow Session\n",
    "        :param learning_rate: 学习率\n",
    "        :param training_batches: 用于训练的batch数\n",
    "        :param batches_per_validate_data: 训练多少个batch对validation数据进行一次验证\n",
    "        :param save_model: 存储模型\n",
    "        \"\"\"\n",
    "        \n",
    "        # 定义输出label\n",
    "        labels = tf.placeholder(tf.float32, [None, 10])\n",
    "        \n",
    "        # 定义损失函数\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, \n",
    "                                                                                  logits=self.output_layer))\n",
    "        \n",
    "        # 准确率\n",
    "        correct_prediction = tf.equal(tf.argmax(self.output_layer, 1), tf.argmax(labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        #\n",
    "        if self.use_batch_norm:\n",
    "            with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "                train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "            \n",
    "        else:\n",
    "            train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "        \n",
    "        # 显示进度条\n",
    "        for i in tqdm.tqdm(range(training_batches)):\n",
    "            batch_x, batch_y = mnist.train.next_batch(60)\n",
    "            sess.run(train_step, feed_dict={self.input_layer: batch_x,\n",
    "                                            labels: batch_y,\n",
    "                                            self.is_training: True})\n",
    "            if i % batches_per_validate_data == 0:\n",
    "                val_accuracy = sess.run(accuracy, feed_dict={self.input_layer: mnist.validation.images,\n",
    "                                                              labels: mnist.validation.labels,\n",
    "                                                              self.is_training: False})\n",
    "                self.training_accuracies.append(val_accuracy)\n",
    "        print(\"{}: The final accuracy on validation data is {}\".format(self.name, val_accuracy))\n",
    "        \n",
    "        # 存储模型\n",
    "        if save_model:\n",
    "            tf.train.Saver().save(sess, save_model)\n",
    "    \n",
    "    def test(self, sess, test_training_accuracy=False, restore=None):\n",
    "        # 定义label\n",
    "        labels = tf.placeholder(tf.float32, [None, 10])\n",
    "        \n",
    "        # 准确率\n",
    "        correct_prediction = tf.equal(tf.argmax(self.output_layer, 1), tf.argmax(labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        # 是否加载模型\n",
    "        if restore:\n",
    "            tf.train.Saver().restore(sess, restore)\n",
    "        \n",
    "        test_accuracy = sess.run(accuracy, feed_dict={self.input_layer: mnist.test.images,\n",
    "                                                      labels: mnist.test.labels,\n",
    "                                                      self.is_training: False})\n",
    "        \n",
    "        print(\"{}: The final accuracy on test data is {}\".format(self.name, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
